{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, mutual_info_regression, SelectPercentile, VarianceThreshold\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import multiprocessing\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "sys.path.append('../../../')\n",
    "\n",
    "from src.emotion.prediction.aggregates.train import HyperparaSearch\n",
    "from src.emotion.prediction.aggregates.models import MODELS\n",
    "from src.emotion.utils.constants import DATA_DIR\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('/home/moritz/Workspace/masterthesis/data/features_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('/home/moritz/Workspace/masterthesis/data/perma_scores_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 9351)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(features, targets, on=[\"E-Mail-Adresse\", \"Day\"])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 9348)\n"
     ]
    }
   ],
   "source": [
    "# Handle Missing Values\n",
    "\n",
    "df.dropna(axis=1, how='any', inplace=True)\n",
    "#df = dataset.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 9348)\n",
      "(104, 8759)\n",
      "(104, 8759)\n"
     ]
    }
   ],
   "source": [
    "# Detect outliers\n",
    "\n",
    "# Check if all PERMA values are the same in each row\n",
    "same_PERMA = (df['P'] == df['E']) & (df['E'] == df['R']) & (df['R'] == df['M']) & (df['M'] == df['A'])\n",
    "# Remove the rows where all PERMA values are the same\n",
    "df = df[~same_PERMA]\n",
    "print(df.shape)\n",
    "\n",
    "# find columns where all values are the same\n",
    "cols_to_drop = [col for col in df.columns if df[col].nunique() == 1]\n",
    "# drop the columns\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df.shape)\n",
    "\n",
    "# drop columns where all values are only 0 or 1\n",
    "df = df.loc[:, ~(df.isin([0, 1]).all() & ~df.isin([0, 1]).any())]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and Y\n",
    "# Store the PERMA values in Y\n",
    "Y = df[['P', 'E', 'R', 'M', 'A']]\n",
    "\n",
    "# Store the other columns in X\n",
    "X = df.drop(columns=['ClassID', 'E-Mail-Adresse', 'Day', 'First Name', 'Last Name/Surname', 'P', 'E', 'R', 'M', 'A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Features\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the dataframe and transform the dataframe\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(matrix):\n",
    "    # center the matrix\n",
    "    matrix = matrix - np.mean(matrix, axis=0)\n",
    "\n",
    "    # transpose the matrix\n",
    "    matrix_t = matrix.T\n",
    "\n",
    "    # compute the correlation matrix using np.corrcoef\n",
    "    corr_matrix = np.corrcoef(matrix_t)\n",
    "\n",
    "    # create a heatmap of the correlation matrix using seaborn\n",
    "    sns.set(font_scale=0.7)\n",
    "    sns.heatmap(corr_matrix, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_correlation_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection: runs in ~ 5min \n",
    "# Step 1: Identify feature clusters\n",
    "# Create a dendrogram using hierarchical clustering\n",
    "linkage = hierarchy.linkage(corr_matrix, method='complete')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Data points')\n",
    "plt.ylabel('Distance')\n",
    "hierarchy.dendrogram(\n",
    "    linkage,\n",
    "    leaf_rotation=0.,  # Rotate x-axis labels\n",
    "    leaf_font_size=12.,  # Font size for x-axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clusters from the dendrogram\n",
    "max_d = 15 # Maximum distance between clusters\n",
    "clusters = hierarchy.fcluster(linkage, max_d, criterion='distance')\n",
    "\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group columns by cluster\n",
    "df = pd.DataFrame(corr_matrix)\n",
    "df.columns = ['col_' + str(i) for i in range(df.shape[1])]\n",
    "df['cluster'] = clusters\n",
    "grouped = df.groupby('cluster')\n",
    "\n",
    "# Get the size of each group\n",
    "group_sizes = grouped.size()\n",
    "\n",
    "# Plot the group sizes\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(x=group_sizes.index, height=group_sizes.values, color='blue')\n",
    "plt.title('Group Sizes')\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Size')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "print(X.shape)\n",
    "print(len(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Calculate the correlation matrix between the columns of X and the columns of Y\n",
    "corr_matrix = np.abs(np.corrcoef(X.T, Y.T)[:X.shape[1], X.shape[1]:])\n",
    "\n",
    "# compute the row-wise averages of the matrix\n",
    "avg_matrix = np.mean(corr_matrix, axis=1, keepdims=True)\n",
    "\n",
    "# concatenate the average matrix with the group array\n",
    "concat_matrix = np.concatenate([avg_matrix, clusters.reshape(len(clusters), 1)], axis=1)\n",
    "\n",
    "# sort the concatenated matrix by group\n",
    "sorted_matrix = concat_matrix[concat_matrix[:, -1].argsort()]\n",
    "\n",
    "# find the maximum value in each group and its index\n",
    "max_values = []\n",
    "# iterate over the unique groups in the second column of the sorted matrix\n",
    "for group in np.unique(sorted_matrix[:, 1]):\n",
    "    # find the indices of rows that belong to the current group\n",
    "    indices = np.where(sorted_matrix[:, 1] == group)[0]\n",
    "    # get the maximum value in the first column for the current group\n",
    "    max_value = np.max(sorted_matrix[indices, 0])\n",
    "    # append the maximum value to the list\n",
    "    max_values.append(max_value)\n",
    "    \n",
    "    \n",
    "# find the indices of all the maximum values in the avg_matrix\n",
    "max_indices = []\n",
    "for max_value in max_values:\n",
    "    indices = np.where(avg_matrix == max_value)[0]\n",
    "    max_indices.extend(indices)\n",
    "\n",
    "X_filtered = X.iloc[:, max_indices]\n",
    "print(X_filtered.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(X_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensemble feature selection (using voting) across multiple filter methods\n",
    "# # TODO: Maybe create seperate feature sets for each PERMA dimension seperatly?\n",
    "# def get_selected_features(Y, X_filtered, filter_methods):\n",
    "#     selected_features = []\n",
    "    \n",
    "#     for i in range(Y.shape[1]):\n",
    "#         y_i = Y.iloc[:, i]\n",
    "#         selected_i = []\n",
    "        \n",
    "#         for method_name, method in filter_methods.items():\n",
    "#             pipeline = Pipeline([(method_name, method), ('regressor', LinearRegression())])\n",
    "#             pipeline.fit(X_filtered, y_i)\n",
    "#             selected_i.append(pipeline.named_steps[method_name].get_support(indices=True))\n",
    "        \n",
    "#         selected_i = np.concatenate(selected_i)\n",
    "#         selected_i = np.unique(selected_i)\n",
    "#         selected_features.append(selected_i)\n",
    "        \n",
    "#     return np.concatenate(selected_features)\n",
    "\n",
    "# filter_methods = {\n",
    "#     'f_regression': SelectKBest(f_regression, k=1),\n",
    "#     'mutual_info_regression': SelectKBest(mutual_info_regression, k=1),\n",
    "#     'variance_threshold': VarianceThreshold(threshold=0.1),\n",
    "# }\n",
    "\n",
    "# all_selected_features = get_selected_features(Y, X_filtered, filter_methods)\n",
    "\n",
    "# print(\"Fused selected features:\", all_selected_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_voting_features_multi(Y, X_filtered, filter_methods, k):\n",
    "    feature_counts = np.zeros(X_filtered.shape[1])\n",
    "    \n",
    "    #print(Y.shape[1])\n",
    "    print(len(Y.T))\n",
    "    \n",
    "    for i in range(len(Y.T)):\n",
    "        y_i = Y.iloc[:, i]\n",
    "        \n",
    "        for method_name, method in filter_methods.items():\n",
    "            pipeline = Pipeline([(method_name, method), ('regressor', LinearRegression())])\n",
    "            pipeline.fit(X_filtered, y_i)\n",
    "            selected_i = pipeline.named_steps[method_name].get_support(indices=True)\n",
    "            \n",
    "            # Increment the count for each selected feature\n",
    "            for index in selected_i:\n",
    "                feature_counts[index] += 1\n",
    "                \n",
    "    # Get the indices of the top k features with the most counts\n",
    "    top_k_features = np.argsort(feature_counts)[-k:]\n",
    "    \n",
    "    return top_k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_methods = {\n",
    "    'f_regression': SelectKBest(f_regression, k=10),\n",
    "    'mutual_info_regression': SelectKBest(mutual_info_regression, k=10),\n",
    "    'variance_threshold': VarianceThreshold(threshold=0.1),\n",
    "}\n",
    "\n",
    "all_selected_features = get_selected_voting_features_multi(Y, X_filtered, filter_methods, k=15)\n",
    "\n",
    "print(\"Fused selected features:\", all_selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = X_filtered.iloc[:, list(set(all_selected_features))]\n",
    "plot_correlation_matrix(X_final)\n",
    "column_names = X_final.columns.tolist()\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_drop = [\"MLPRegressor\", \"KNeighborsRegressor\", \"DecisionTreeRegressor\", \"GradientBoostingRegressor\", \"SVR\"]\n",
    "\n",
    "for name in models_to_drop:\n",
    "    for i in range(len(MODELS)):\n",
    "        if MODELS[i][\"name\"] == name:\n",
    "            del MODELS[i]\n",
    "            break\n",
    "        \n",
    "for model in MODELS:\n",
    "    print(model[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs in ~5 min for n_fols=5\n",
    "search = HyperparaSearch(models=MODELS, metrics=[\"mean_absolute_error\"], n_folds=5, n_jobs=-1)\n",
    "\n",
    "results = search.run(X_final, Y, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_feats_dict = {model[0]['name']: model[0]['best_feats'] for model in results}\n",
    "#print(best_feats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in best_feats_dict.keys():\n",
    "    print(f\"Algorithm: {model}\")\n",
    "    # Get the feature importance values for the algorithm\n",
    "    feat_imp_vals = best_feats_dict[model]\n",
    "    # Map the feature importance values with the feature list using a dictionary comprehension\n",
    "    feat_imp_map = {column_names[i]: feat_imp_vals[i] for i in range(len(column_names))}\n",
    "    # Rank the features by their importance value in descending order\n",
    "    ranked_feats = sorted(feat_imp_map.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Print the ranked features\n",
    "    #print(ranked_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric = \"mean_absolute_error\"\n",
    "\n",
    "# Plot the results\n",
    "mae_scores = [\n",
    "    rd[\"score\"]\n",
    "    for result_list in results\n",
    "    for rd in result_list\n",
    "    if rd[\"metric\"] == eval_metric\n",
    "]\n",
    "model_names = [\n",
    "    rd[\"name\"]\n",
    "    for result_list in results\n",
    "    for rd in result_list\n",
    "    if rd[\"metric\"] == eval_metric\n",
    "]\n",
    "plt.bar(model_names, mae_scores)\n",
    "plt.title(\"Mean Absolute Error Scores\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks(rotation=45) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the model with the lowest score\n",
    "best_model = min(\n",
    "    [\n",
    "        min(\n",
    "            sublist,\n",
    "            key=lambda x: x[\"score\"]\n",
    "            if x[\"metric\"] == eval_metric\n",
    "            else float(\"inf\"),\n",
    "        )\n",
    "        for sublist in results\n",
    "    ],\n",
    "    key=lambda x: x[\"score\"],\n",
    ")\n",
    "print(f\"Best model: {best_model['name']}\")\n",
    "print(f\"Best params: {best_model['params']}\")\n",
    "print(f\"Best Score: {best_model['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_voting_features_uni(Y, X_filtered, filter_methods, k):\n",
    "    feature_counts = np.zeros(X_filtered.shape[1])\n",
    "        \n",
    "    for method_name, method in filter_methods.items():\n",
    "        pipeline = Pipeline([(method_name, method), ('regressor', LinearRegression())])\n",
    "        pipeline.fit(X_filtered, Y)\n",
    "        selected_i = pipeline.named_steps[method_name].get_support(indices=True)\n",
    "        \n",
    "        # Increment the count for each selected feature\n",
    "        for index in selected_i:\n",
    "            feature_counts[index] += 1\n",
    "                \n",
    "    # Get the indices of the top k features with the most counts\n",
    "    top_k_features = np.argsort(feature_counts)[-k:]\n",
    "    \n",
    "    return top_k_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for each PERMA pillar\n",
    "perma_dict = {\n",
    "    \"P\": None,\n",
    "    \"E\": None,\n",
    "    \"R\": None,\n",
    "    \"M\": None,\n",
    "    \"A\": None,\n",
    "}\n",
    "\n",
    "filter_methods = {\n",
    "    'f_regression': SelectKBest(f_regression, k=10),\n",
    "    'mutual_info_regression': SelectKBest(mutual_info_regression, k=10),\n",
    "    'variance_threshold': VarianceThreshold(threshold=0.1),\n",
    "}\n",
    "\n",
    "# Iterate over each PERMA dimension in Y\n",
    "for i, perma_dim in enumerate(Y.columns):\n",
    "    # Get the selected features for the current PERMA dimension\n",
    "    selected_features = get_selected_voting_features_uni(Y.iloc[:, i], X_filtered, filter_methods, k=10)\n",
    "    # Save the selected features in the corresponding dictionary for the current PERMA pillar\n",
    "    perma_dict[perma_dim] = selected_features\n",
    "\n",
    "# Print the selected features for each PERMA dimension in each PERMA pillar\n",
    "for pillar in perma_dict:\n",
    "    print(pillar, \":\", perma_dict[pillar])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {}\n",
    "\n",
    "for perma_dim, selected_features in perma_dict.items():\n",
    "    # Select the corresponding columns of X_filtered\n",
    "    X_final = X_filtered.iloc[:, list(set(selected_features))]\n",
    "    # Add the selected features for the current PERMA dimension to the feature sets dictionary\n",
    "    feature_sets[perma_dim] = X_final\n",
    "    # Print the names of the selected features\n",
    "    column_names = X_final.columns.tolist()\n",
    "    print(perma_dim, \":\", column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    {\n",
    "        \"name\": \"RandomForestRegressor\",\n",
    "        \"model\": RandomForestRegressor(),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200, 400], \"max_depth\": range(2, 6)},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ExtraTreesRegressor\",\n",
    "        \"model\": ExtraTreesRegressor(),\n",
    "        \"params\": {\"n_estimators\": [50, 100, 200, 400], \"max_depth\": range(2, 6)},\n",
    "    },\n",
    "    # {\n",
    "    #     \"name\": \"GradientBoostingRegressor\",\n",
    "    #     \"model\": GradientBoostingRegressor(),\n",
    "    #     \"params\": {\n",
    "    #         \"n_estimators\": [50, 100, 200, 400],\n",
    "    #         \"max_depth\": range(2, 6),\n",
    "    #         \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "    #     },\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"AdaBoostRegressor\",\n",
    "    #     \"model\": AdaBoostRegressor(),\n",
    "    #     \"params\": {\n",
    "    #         \"n_estimators\": [50, 100, 200, 400],\n",
    "    #         \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "    #     },\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"LinearRegression\",\n",
    "        \"model\": LinearRegression(),\n",
    "        \"params\": {},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Ridge\",\n",
    "        \"model\": Ridge(),\n",
    "        \"params\": {\"alpha\": [0.001, 0.01, 0.1, 1.0]},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Lasso\",\n",
    "        \"model\": Lasso(),\n",
    "        \"params\": {\"alpha\": [0.001, 0.01, 0.1, 1.0]},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ElasticNet\",\n",
    "        \"model\": ElasticNet(),\n",
    "        \"params\": {\"alpha\": [0.001, 0.01, 0.1, 1.0], \"l1_ratio\": [0.1, 0.5, 0.9]},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BayesianRidge\",\n",
    "        \"model\": BayesianRidge(),\n",
    "        \"params\": {\n",
    "            \"alpha_1\": [0.001, 0.01, 0.1, 1.0],\n",
    "            \"alpha_2\": [0.001, 0.01, 0.1, 1.0],\n",
    "        },\n",
    "    },\n",
    "    # {\n",
    "    #     \"name\": \"CatBoostRegressor\",\n",
    "    #     \"model\": CatBoostRegressor(verbose=False),\n",
    "    #     \"params\": {\n",
    "    #         \"iterations\": [50, 100, 200, 400],\n",
    "    #         \"depth\": range(2, 6),\n",
    "    #         \"learning_rate\": [0.001, 0.01, 0.1, 1.0],\n",
    "    #     },\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"XGBRegressor\",\n",
    "        \"model\": XGBRegressor(),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200, 400],\n",
    "            \"max_depth\": range(2, 6),\n",
    "            \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for perma_dim, X_final in feature_sets.items():\n",
    "    print(f\"PERMA dimension: {perma_dim}\")\n",
    "    # Run the hyperparameter search\n",
    "    search = HyperparaSearch(models=MODELS, metrics=[\"mean_absolute_error\"], n_folds=5, n_jobs=-1, mode=\"uni\", verbose=False)\n",
    "    results = search.run(X_final, Y[perma_dim], save=False)\n",
    "    # Print the model with the lowest score\n",
    "    best_model = min(\n",
    "        [\n",
    "            min(\n",
    "                sublist,\n",
    "                key=lambda x: x[\"score\"]\n",
    "                if x[\"metric\"] == eval_metric\n",
    "                else float(\"inf\"),\n",
    "            )\n",
    "            for sublist in results\n",
    "        ],\n",
    "        key=lambda x: x[\"score\"],\n",
    "    )\n",
    "    print(perma_dim)\n",
    "    print(f\"Best model: {best_model['name']}\")\n",
    "    print(f\"Best params: {best_model['params']}\")\n",
    "    print(f\"Best Score: {best_model['score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emorec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c67f0142598d7b06f34a2acb15d98e76cb3b1e66b7b86f21a91e42da5de8188"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
